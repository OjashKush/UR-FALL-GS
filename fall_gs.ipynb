{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OjashKush/UR-FALL-GS/blob/main/fall_gs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEWfzQFpZNyK",
        "outputId": "c23d02c8-9887-4387-a36c-8b430cac30a2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.8)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.13.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch_geometric) (4.12.2)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import time\n",
        "import pickle\n",
        "\n",
        "import os\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "\n",
        "# Define the base URL and local directory\n",
        "base_url = \"http://fenix.ur.edu.pl/~mkepski/ds/data/\"\n",
        "local_dir = \"/content/urfall_dataset\"\n",
        "\n",
        "\n",
        "def download_and_extract(file_name):\n",
        "    \"\"\"Download and extract a zip file.\"\"\"\n",
        "    url = base_url + file_name\n",
        "    zip_path = os.path.join(local_dir, file_name)\n",
        "\n",
        "    # Download the file\n",
        "    print(f\"Downloading {file_name}...\")\n",
        "    urllib.request.urlretrieve(url, zip_path)\n",
        "\n",
        "    # Extract the file\n",
        "    print(f\"Extracting {file_name}...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(local_dir)\n",
        "\n",
        "    # Remove the zip file\n",
        "    os.remove(zip_path)\n",
        "\n",
        "def prepare_dataset():\n",
        "    \"\"\"Prepare the UR Fall dataset.\"\"\"\n",
        "\n",
        "    # Create the local directory if it doesn't exist\n",
        "    os.makedirs(local_dir, exist_ok=True)\n",
        "\n",
        "    # Download and extract depth data for falls\n",
        "    for i in range(1, 31):\n",
        "        file_name = f\"fall-{i:02d}-cam0-d.zip\"\n",
        "        download_and_extract(file_name)\n",
        "\n",
        "    # Download and extract depth data for ADLs\n",
        "    for i in range(1, 41):\n",
        "        file_name = f\"adl-{i:02d}-cam0-d.zip\"\n",
        "        download_and_extract(file_name)\n",
        "\n",
        "def process_data():\n",
        "    \"\"\"Process the downloaded data and create CSV files.\"\"\"\n",
        "    fall_data = []\n",
        "    adl_data = []\n",
        "\n",
        "    # Process fall data\n",
        "    for i in range(1, 31):\n",
        "        folder = os.path.join(local_dir, f\"fall-{i:02d}-cam0-d\")\n",
        "        if os.path.exists(folder):\n",
        "            for file in os.listdir(folder):\n",
        "                if file.endswith('.png'):\n",
        "                    fall_data.append({'file': os.path.join(folder, file), 'label': 1})\n",
        "\n",
        "    # Process ADL data\n",
        "    for i in range(1, 41):\n",
        "        folder = os.path.join(local_dir, f\"adl-{i:02d}-cam0-d\")\n",
        "        if os.path.exists(folder):\n",
        "            for file in os.listdir(folder):\n",
        "                if file.endswith('.png'):\n",
        "                    adl_data.append({'file': os.path.join(folder, file), 'label': 0})\n",
        "\n",
        "    # Combine and shuffle data\n",
        "    all_data = fall_data + adl_data\n",
        "    np.random.shuffle(all_data)\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(all_data)\n",
        "\n",
        "    return df\n",
        "\n",
        "def split_dataset(df, test_size=0.2, random_state=42):\n",
        "    \"\"\"Split the dataset into train and test sets.\"\"\"\n",
        "\n",
        "    # Split the data\n",
        "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state, stratify=df['label'])\n",
        "\n",
        "    # Save the split datasets\n",
        "    train_df.to_csv(os.path.join(local_dir, \"train_data.csv\"), index=False)\n",
        "    test_df.to_csv(os.path.join(local_dir, \"test_data.csv\"), index=False)\n",
        "\n",
        "    print(f\"Train set size: {len(train_df)}\")\n",
        "    print(f\"Test set size: {len(test_df)}\")\n",
        "\n",
        "    return train_df, test_df\n",
        "\n",
        "class URFallDataset(Dataset):\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        file_path = self.dataframe.iloc[idx]['file']\n",
        "        label = self.dataframe.iloc[idx]['label']\n",
        "\n",
        "        # Load image using PIL\n",
        "        image = Image.open(file_path).convert('L')  # Convert to grayscale\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "# Data transformations\n",
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Resize images to a fixed size\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "class MotionModule(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MotionModule, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.pool(x)\n",
        "        return x\n",
        "\n",
        "class GSTCAN(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(GSTCAN, self).__init__()\n",
        "        self.motion_module = MotionModule()\n",
        "        self.gcn_layer = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=1)\n",
        "        self.tcn_layer = nn.Conv1d(in_channels=128, out_channels=256, kernel_size=3, padding=1)\n",
        "        self.cam_layer = nn.Sequential(\n",
        "            nn.Conv1d(256, 256, kernel_size=1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        motion_features = self.motion_module(x)\n",
        "        gcn_output = self.gcn_layer(motion_features)\n",
        "        tcn_input = gcn_output.view(gcn_output.size(0), gcn_output.size(1), -1)\n",
        "        tcn_output = self.tcn_layer(tcn_input)\n",
        "        cam_output = self.cam_layer(tcn_output)\n",
        "        pooled_features = self.gap(cam_output.unsqueeze(-1))\n",
        "        output = self.classifier(pooled_features.view(pooled_features.size(0), -1))\n",
        "        return output\n",
        "\n",
        "def save_checkpoint(model, optimizer, epoch, train_loss, test_accuracy, filename):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'train_loss': train_loss,\n",
        "        'test_accuracy': test_accuracy\n",
        "    }\n",
        "    torch.save(checkpoint, filename)\n",
        "\n",
        "def load_checkpoint(model, optimizer, filename):\n",
        "    checkpoint = torch.load(filename)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    return checkpoint['epoch'], checkpoint['train_loss'], checkpoint['test_accuracy']\n",
        "\n",
        "def save_transforms(transforms, filename):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(transforms, f)\n",
        "\n",
        "def load_transforms(filename):\n",
        "    with open(filename, 'rb') as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "def train_model(model, train_loader, test_loader, num_epochs=10, checkpoint_dir='checkpoints'):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    # Check if there's a checkpoint to resume from\n",
        "    checkpoints = [f for f in os.listdir(checkpoint_dir) if f.startswith('checkpoint_epoch_')]\n",
        "    if checkpoints:\n",
        "        latest_checkpoint = max(checkpoints, key=lambda x: int(x.split('_')[2].split('.')[0]))\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, latest_checkpoint)\n",
        "        start_epoch, train_loss, best_accuracy = load_checkpoint(model, optimizer, checkpoint_path)\n",
        "        print(f\"Resuming from epoch {start_epoch} with best accuracy: {best_accuracy:.2f}%\")\n",
        "        start_epoch += 1  # Start from the next epoch\n",
        "\n",
        "    total_start_time = time.time()\n",
        "\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        model.train()\n",
        "        epoch_start_time = time.time()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            if batch_idx % 10 == 0:\n",
        "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "\n",
        "        # Testing loop\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in test_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                _, predicted = torch.max(output.data, 1)\n",
        "                total += target.size(0)\n",
        "                correct += (predicted == target).sum().item()\n",
        "\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Test accuracy: {accuracy:.2f}%')\n",
        "\n",
        "        # Save checkpoint\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pth')\n",
        "        save_checkpoint(model, optimizer, epoch+1, epoch_loss, accuracy, checkpoint_path)\n",
        "\n",
        "        if accuracy > best_accuracy:\n",
        "            best_accuracy = accuracy\n",
        "            best_model_path = os.path.join(checkpoint_dir, 'best_model.pth')\n",
        "            torch.save(model.state_dict(), best_model_path)\n",
        "\n",
        "        epoch_end_time = time.time()\n",
        "        epoch_duration = epoch_end_time - epoch_start_time\n",
        "        estimated_time_left = epoch_duration * (num_epochs - epoch - 1)\n",
        "\n",
        "        print(f'Epoch duration: {epoch_duration:.2f} seconds')\n",
        "        print(f'Estimated time left: {estimated_time_left/60:.2f} minutes')\n",
        "\n",
        "    total_end_time = time.time()\n",
        "    total_duration = total_end_time - total_start_time\n",
        "    print(f'Total training time: {total_duration/60:.2f} minutes')\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    prepare_dataset()\n",
        "    df = process_data()\n",
        "    train_df, test_df = split_dataset(df)\n",
        "\n",
        "    # Create and save the data transforms\n",
        "    data_transforms = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "    ])\n",
        "    save_transforms(data_transforms, 'data_transforms.pkl')\n",
        "\n",
        "    train_dataset = URFallDataset(train_df, transform=data_transforms)\n",
        "    test_dataset = URFallDataset(test_df, transform=data_transforms)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    model = GSTCAN(num_classes=2)\n",
        "    train_model(model, train_loader, test_loader)\n",
        "\n",
        "    print(\"Dataset preparation and model training completed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-D9CIbaOaGr",
        "outputId": "d7ac5363-bd19-4455-c269-6b2918c5e894"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading fall-01-cam0-d.zip...\n",
            "Extracting fall-01-cam0-d.zip...\n",
            "Downloading fall-02-cam0-d.zip...\n",
            "Extracting fall-02-cam0-d.zip...\n",
            "Downloading fall-03-cam0-d.zip...\n",
            "Extracting fall-03-cam0-d.zip...\n",
            "Downloading fall-04-cam0-d.zip...\n",
            "Extracting fall-04-cam0-d.zip...\n",
            "Downloading fall-05-cam0-d.zip...\n",
            "Extracting fall-05-cam0-d.zip...\n",
            "Downloading fall-06-cam0-d.zip...\n",
            "Extracting fall-06-cam0-d.zip...\n",
            "Downloading fall-07-cam0-d.zip...\n",
            "Extracting fall-07-cam0-d.zip...\n",
            "Downloading fall-08-cam0-d.zip...\n",
            "Extracting fall-08-cam0-d.zip...\n",
            "Downloading fall-09-cam0-d.zip...\n",
            "Extracting fall-09-cam0-d.zip...\n",
            "Downloading fall-10-cam0-d.zip...\n",
            "Extracting fall-10-cam0-d.zip...\n",
            "Downloading fall-11-cam0-d.zip...\n",
            "Extracting fall-11-cam0-d.zip...\n",
            "Downloading fall-12-cam0-d.zip...\n",
            "Extracting fall-12-cam0-d.zip...\n",
            "Downloading fall-13-cam0-d.zip...\n",
            "Extracting fall-13-cam0-d.zip...\n",
            "Downloading fall-14-cam0-d.zip...\n",
            "Extracting fall-14-cam0-d.zip...\n",
            "Downloading fall-15-cam0-d.zip...\n",
            "Extracting fall-15-cam0-d.zip...\n",
            "Downloading fall-16-cam0-d.zip...\n",
            "Extracting fall-16-cam0-d.zip...\n",
            "Downloading fall-17-cam0-d.zip...\n",
            "Extracting fall-17-cam0-d.zip...\n",
            "Downloading fall-18-cam0-d.zip...\n",
            "Extracting fall-18-cam0-d.zip...\n",
            "Downloading fall-19-cam0-d.zip...\n",
            "Extracting fall-19-cam0-d.zip...\n",
            "Downloading fall-20-cam0-d.zip...\n",
            "Extracting fall-20-cam0-d.zip...\n",
            "Downloading fall-21-cam0-d.zip...\n",
            "Extracting fall-21-cam0-d.zip...\n",
            "Downloading fall-22-cam0-d.zip...\n",
            "Extracting fall-22-cam0-d.zip...\n",
            "Downloading fall-23-cam0-d.zip...\n",
            "Extracting fall-23-cam0-d.zip...\n",
            "Downloading fall-24-cam0-d.zip...\n",
            "Extracting fall-24-cam0-d.zip...\n",
            "Downloading fall-25-cam0-d.zip...\n",
            "Extracting fall-25-cam0-d.zip...\n",
            "Downloading fall-26-cam0-d.zip...\n",
            "Extracting fall-26-cam0-d.zip...\n",
            "Downloading fall-27-cam0-d.zip...\n",
            "Extracting fall-27-cam0-d.zip...\n",
            "Downloading fall-28-cam0-d.zip...\n",
            "Extracting fall-28-cam0-d.zip...\n",
            "Downloading fall-29-cam0-d.zip...\n",
            "Extracting fall-29-cam0-d.zip...\n",
            "Downloading fall-30-cam0-d.zip...\n",
            "Extracting fall-30-cam0-d.zip...\n",
            "Downloading adl-01-cam0-d.zip...\n",
            "Extracting adl-01-cam0-d.zip...\n",
            "Downloading adl-02-cam0-d.zip...\n",
            "Extracting adl-02-cam0-d.zip...\n",
            "Downloading adl-03-cam0-d.zip...\n",
            "Extracting adl-03-cam0-d.zip...\n",
            "Downloading adl-04-cam0-d.zip...\n",
            "Extracting adl-04-cam0-d.zip...\n",
            "Downloading adl-05-cam0-d.zip...\n",
            "Extracting adl-05-cam0-d.zip...\n",
            "Downloading adl-06-cam0-d.zip...\n",
            "Extracting adl-06-cam0-d.zip...\n",
            "Downloading adl-07-cam0-d.zip...\n",
            "Extracting adl-07-cam0-d.zip...\n",
            "Downloading adl-08-cam0-d.zip...\n",
            "Extracting adl-08-cam0-d.zip...\n",
            "Downloading adl-09-cam0-d.zip...\n",
            "Extracting adl-09-cam0-d.zip...\n",
            "Downloading adl-10-cam0-d.zip...\n",
            "Extracting adl-10-cam0-d.zip...\n",
            "Downloading adl-11-cam0-d.zip...\n",
            "Extracting adl-11-cam0-d.zip...\n",
            "Downloading adl-12-cam0-d.zip...\n",
            "Extracting adl-12-cam0-d.zip...\n",
            "Downloading adl-13-cam0-d.zip...\n",
            "Extracting adl-13-cam0-d.zip...\n",
            "Downloading adl-14-cam0-d.zip...\n",
            "Extracting adl-14-cam0-d.zip...\n",
            "Downloading adl-15-cam0-d.zip...\n",
            "Extracting adl-15-cam0-d.zip...\n",
            "Downloading adl-16-cam0-d.zip...\n",
            "Extracting adl-16-cam0-d.zip...\n",
            "Downloading adl-17-cam0-d.zip...\n",
            "Extracting adl-17-cam0-d.zip...\n",
            "Downloading adl-18-cam0-d.zip...\n",
            "Extracting adl-18-cam0-d.zip...\n",
            "Downloading adl-19-cam0-d.zip...\n",
            "Extracting adl-19-cam0-d.zip...\n",
            "Downloading adl-20-cam0-d.zip...\n",
            "Extracting adl-20-cam0-d.zip...\n",
            "Downloading adl-21-cam0-d.zip...\n",
            "Extracting adl-21-cam0-d.zip...\n",
            "Downloading adl-22-cam0-d.zip...\n",
            "Extracting adl-22-cam0-d.zip...\n",
            "Downloading adl-23-cam0-d.zip...\n",
            "Extracting adl-23-cam0-d.zip...\n",
            "Downloading adl-24-cam0-d.zip...\n",
            "Extracting adl-24-cam0-d.zip...\n",
            "Downloading adl-25-cam0-d.zip...\n",
            "Extracting adl-25-cam0-d.zip...\n",
            "Downloading adl-26-cam0-d.zip...\n",
            "Extracting adl-26-cam0-d.zip...\n",
            "Downloading adl-27-cam0-d.zip...\n",
            "Extracting adl-27-cam0-d.zip...\n",
            "Downloading adl-28-cam0-d.zip...\n",
            "Extracting adl-28-cam0-d.zip...\n",
            "Downloading adl-29-cam0-d.zip...\n",
            "Extracting adl-29-cam0-d.zip...\n",
            "Downloading adl-30-cam0-d.zip...\n",
            "Extracting adl-30-cam0-d.zip...\n",
            "Downloading adl-31-cam0-d.zip...\n",
            "Extracting adl-31-cam0-d.zip...\n",
            "Downloading adl-32-cam0-d.zip...\n",
            "Extracting adl-32-cam0-d.zip...\n",
            "Downloading adl-33-cam0-d.zip...\n",
            "Extracting adl-33-cam0-d.zip...\n",
            "Downloading adl-34-cam0-d.zip...\n",
            "Extracting adl-34-cam0-d.zip...\n",
            "Downloading adl-35-cam0-d.zip...\n",
            "Extracting adl-35-cam0-d.zip...\n",
            "Downloading adl-36-cam0-d.zip...\n",
            "Extracting adl-36-cam0-d.zip...\n",
            "Downloading adl-37-cam0-d.zip...\n",
            "Extracting adl-37-cam0-d.zip...\n",
            "Downloading adl-38-cam0-d.zip...\n",
            "Extracting adl-38-cam0-d.zip...\n",
            "Downloading adl-39-cam0-d.zip...\n",
            "Extracting adl-39-cam0-d.zip...\n",
            "Downloading adl-40-cam0-d.zip...\n",
            "Extracting adl-40-cam0-d.zip...\n",
            "Train set size: 9460\n",
            "Test set size: 2366\n",
            "Epoch [1/10], Step [1/296], Loss: 0.7097\n",
            "Epoch [1/10], Step [11/296], Loss: 0.5624\n",
            "Epoch [1/10], Step [21/296], Loss: 0.5599\n",
            "Epoch [1/10], Step [31/296], Loss: 0.5888\n",
            "Epoch [1/10], Step [41/296], Loss: 0.6170\n",
            "Epoch [1/10], Step [51/296], Loss: 0.5039\n",
            "Epoch [1/10], Step [61/296], Loss: 0.5614\n",
            "Epoch [1/10], Step [71/296], Loss: 0.4489\n",
            "Epoch [1/10], Step [81/296], Loss: 0.4728\n",
            "Epoch [1/10], Step [91/296], Loss: 0.4977\n",
            "Epoch [1/10], Step [101/296], Loss: 0.5664\n",
            "Epoch [1/10], Step [111/296], Loss: 0.5181\n",
            "Epoch [1/10], Step [121/296], Loss: 0.4082\n",
            "Epoch [1/10], Step [131/296], Loss: 0.5178\n",
            "Epoch [1/10], Step [141/296], Loss: 0.5025\n",
            "Epoch [1/10], Step [151/296], Loss: 0.6974\n",
            "Epoch [1/10], Step [161/296], Loss: 0.4706\n",
            "Epoch [1/10], Step [171/296], Loss: 0.5455\n",
            "Epoch [1/10], Step [181/296], Loss: 0.5914\n",
            "Epoch [1/10], Step [191/296], Loss: 0.5562\n",
            "Epoch [1/10], Step [201/296], Loss: 0.4525\n",
            "Epoch [1/10], Step [211/296], Loss: 0.4646\n",
            "Epoch [1/10], Step [221/296], Loss: 0.6434\n",
            "Epoch [1/10], Step [231/296], Loss: 0.6507\n",
            "Epoch [1/10], Step [241/296], Loss: 0.5574\n",
            "Epoch [1/10], Step [251/296], Loss: 0.4920\n",
            "Epoch [1/10], Step [261/296], Loss: 0.4784\n",
            "Epoch [1/10], Step [271/296], Loss: 0.6906\n",
            "Epoch [1/10], Step [281/296], Loss: 0.5885\n",
            "Epoch [1/10], Step [291/296], Loss: 0.4796\n",
            "Epoch [1/10], Loss: 0.5279, Test accuracy: 75.70%\n",
            "Epoch duration: 145.83 seconds\n",
            "Estimated time left: 21.87 minutes\n",
            "Epoch [2/10], Step [1/296], Loss: 0.6164\n",
            "Epoch [2/10], Step [11/296], Loss: 0.5298\n",
            "Epoch [2/10], Step [21/296], Loss: 0.6005\n",
            "Epoch [2/10], Step [31/296], Loss: 0.4298\n",
            "Epoch [2/10], Step [41/296], Loss: 0.5469\n",
            "Epoch [2/10], Step [51/296], Loss: 0.5223\n",
            "Epoch [2/10], Step [61/296], Loss: 0.4526\n",
            "Epoch [2/10], Step [71/296], Loss: 0.4083\n",
            "Epoch [2/10], Step [81/296], Loss: 0.4609\n",
            "Epoch [2/10], Step [91/296], Loss: 0.7965\n",
            "Epoch [2/10], Step [101/296], Loss: 0.4575\n",
            "Epoch [2/10], Step [111/296], Loss: 0.5199\n",
            "Epoch [2/10], Step [121/296], Loss: 0.3605\n",
            "Epoch [2/10], Step [131/296], Loss: 0.4423\n",
            "Epoch [2/10], Step [141/296], Loss: 0.4271\n",
            "Epoch [2/10], Step [151/296], Loss: 0.5545\n",
            "Epoch [2/10], Step [161/296], Loss: 0.4206\n",
            "Epoch [2/10], Step [171/296], Loss: 0.5090\n",
            "Epoch [2/10], Step [181/296], Loss: 0.5181\n",
            "Epoch [2/10], Step [191/296], Loss: 0.5234\n",
            "Epoch [2/10], Step [201/296], Loss: 0.3922\n",
            "Epoch [2/10], Step [211/296], Loss: 0.5743\n",
            "Epoch [2/10], Step [221/296], Loss: 0.4857\n",
            "Epoch [2/10], Step [231/296], Loss: 0.5641\n",
            "Epoch [2/10], Step [241/296], Loss: 0.4003\n",
            "Epoch [2/10], Step [251/296], Loss: 0.4868\n",
            "Epoch [2/10], Step [261/296], Loss: 0.4295\n",
            "Epoch [2/10], Step [271/296], Loss: 0.5161\n",
            "Epoch [2/10], Step [281/296], Loss: 0.6561\n",
            "Epoch [2/10], Step [291/296], Loss: 0.4642\n",
            "Epoch [2/10], Loss: 0.4979, Test accuracy: 76.33%\n",
            "Epoch duration: 147.50 seconds\n",
            "Estimated time left: 19.67 minutes\n",
            "Epoch [3/10], Step [1/296], Loss: 0.4768\n",
            "Epoch [3/10], Step [11/296], Loss: 0.4158\n",
            "Epoch [3/10], Step [21/296], Loss: 0.3909\n",
            "Epoch [3/10], Step [31/296], Loss: 0.5029\n",
            "Epoch [3/10], Step [41/296], Loss: 0.4811\n",
            "Epoch [3/10], Step [51/296], Loss: 0.4297\n",
            "Epoch [3/10], Step [61/296], Loss: 0.4980\n",
            "Epoch [3/10], Step [71/296], Loss: 0.5368\n",
            "Epoch [3/10], Step [81/296], Loss: 0.3534\n",
            "Epoch [3/10], Step [91/296], Loss: 0.4244\n",
            "Epoch [3/10], Step [101/296], Loss: 0.3611\n",
            "Epoch [3/10], Step [111/296], Loss: 0.4213\n",
            "Epoch [3/10], Step [121/296], Loss: 0.4061\n",
            "Epoch [3/10], Step [131/296], Loss: 0.3981\n",
            "Epoch [3/10], Step [141/296], Loss: 0.4907\n",
            "Epoch [3/10], Step [151/296], Loss: 0.5577\n",
            "Epoch [3/10], Step [161/296], Loss: 0.4446\n",
            "Epoch [3/10], Step [171/296], Loss: 0.5031\n",
            "Epoch [3/10], Step [181/296], Loss: 0.4283\n",
            "Epoch [3/10], Step [191/296], Loss: 0.4495\n",
            "Epoch [3/10], Step [201/296], Loss: 0.4009\n",
            "Epoch [3/10], Step [211/296], Loss: 0.2531\n",
            "Epoch [3/10], Step [221/296], Loss: 0.4236\n",
            "Epoch [3/10], Step [231/296], Loss: 0.4644\n",
            "Epoch [3/10], Step [241/296], Loss: 0.5051\n",
            "Epoch [3/10], Step [251/296], Loss: 0.4267\n",
            "Epoch [3/10], Step [261/296], Loss: 0.4894\n",
            "Epoch [3/10], Step [271/296], Loss: 0.3168\n",
            "Epoch [3/10], Step [281/296], Loss: 0.3878\n",
            "Epoch [3/10], Step [291/296], Loss: 0.4203\n",
            "Epoch [3/10], Loss: 0.4612, Test accuracy: 76.88%\n",
            "Epoch duration: 147.48 seconds\n",
            "Estimated time left: 17.21 minutes\n",
            "Epoch [4/10], Step [1/296], Loss: 0.4290\n",
            "Epoch [4/10], Step [11/296], Loss: 0.3335\n",
            "Epoch [4/10], Step [21/296], Loss: 0.5004\n",
            "Epoch [4/10], Step [31/296], Loss: 0.4191\n",
            "Epoch [4/10], Step [41/296], Loss: 0.4768\n",
            "Epoch [4/10], Step [51/296], Loss: 0.5016\n",
            "Epoch [4/10], Step [61/296], Loss: 0.2924\n",
            "Epoch [4/10], Step [71/296], Loss: 0.4293\n",
            "Epoch [4/10], Step [81/296], Loss: 0.3689\n",
            "Epoch [4/10], Step [91/296], Loss: 0.4623\n",
            "Epoch [4/10], Step [101/296], Loss: 0.4921\n",
            "Epoch [4/10], Step [111/296], Loss: 0.4604\n",
            "Epoch [4/10], Step [121/296], Loss: 0.4989\n",
            "Epoch [4/10], Step [131/296], Loss: 0.4914\n",
            "Epoch [4/10], Step [141/296], Loss: 0.5076\n",
            "Epoch [4/10], Step [151/296], Loss: 0.3757\n",
            "Epoch [4/10], Step [161/296], Loss: 0.4081\n",
            "Epoch [4/10], Step [171/296], Loss: 0.3417\n",
            "Epoch [4/10], Step [181/296], Loss: 0.4149\n",
            "Epoch [4/10], Step [191/296], Loss: 0.4842\n",
            "Epoch [4/10], Step [201/296], Loss: 0.4084\n",
            "Epoch [4/10], Step [211/296], Loss: 0.5165\n",
            "Epoch [4/10], Step [221/296], Loss: 0.5248\n",
            "Epoch [4/10], Step [231/296], Loss: 0.4989\n",
            "Epoch [4/10], Step [241/296], Loss: 0.5489\n",
            "Epoch [4/10], Step [251/296], Loss: 0.4380\n",
            "Epoch [4/10], Step [261/296], Loss: 0.6084\n",
            "Epoch [4/10], Step [271/296], Loss: 0.4091\n",
            "Epoch [4/10], Step [281/296], Loss: 0.4424\n",
            "Epoch [4/10], Step [291/296], Loss: 0.4794\n",
            "Epoch [4/10], Loss: 0.4306, Test accuracy: 81.32%\n",
            "Epoch duration: 147.46 seconds\n",
            "Estimated time left: 14.75 minutes\n",
            "Epoch [5/10], Step [1/296], Loss: 0.5755\n",
            "Epoch [5/10], Step [11/296], Loss: 0.4520\n",
            "Epoch [5/10], Step [21/296], Loss: 0.4768\n",
            "Epoch [5/10], Step [31/296], Loss: 0.4762\n",
            "Epoch [5/10], Step [41/296], Loss: 0.3788\n",
            "Epoch [5/10], Step [51/296], Loss: 0.4108\n",
            "Epoch [5/10], Step [61/296], Loss: 0.5149\n",
            "Epoch [5/10], Step [71/296], Loss: 0.4004\n",
            "Epoch [5/10], Step [81/296], Loss: 0.3732\n",
            "Epoch [5/10], Step [91/296], Loss: 0.3116\n",
            "Epoch [5/10], Step [101/296], Loss: 0.4828\n",
            "Epoch [5/10], Step [111/296], Loss: 0.4590\n",
            "Epoch [5/10], Step [121/296], Loss: 0.4923\n",
            "Epoch [5/10], Step [131/296], Loss: 0.3416\n",
            "Epoch [5/10], Step [141/296], Loss: 0.4241\n",
            "Epoch [5/10], Step [151/296], Loss: 0.5496\n",
            "Epoch [5/10], Step [161/296], Loss: 0.4078\n",
            "Epoch [5/10], Step [171/296], Loss: 0.3444\n",
            "Epoch [5/10], Step [181/296], Loss: 0.4387\n",
            "Epoch [5/10], Step [191/296], Loss: 0.3699\n",
            "Epoch [5/10], Step [201/296], Loss: 0.3936\n",
            "Epoch [5/10], Step [211/296], Loss: 0.3380\n",
            "Epoch [5/10], Step [221/296], Loss: 0.3662\n",
            "Epoch [5/10], Step [231/296], Loss: 0.3975\n",
            "Epoch [5/10], Step [241/296], Loss: 0.3210\n",
            "Epoch [5/10], Step [251/296], Loss: 0.4117\n",
            "Epoch [5/10], Step [261/296], Loss: 0.4832\n",
            "Epoch [5/10], Step [271/296], Loss: 0.2621\n",
            "Epoch [5/10], Step [281/296], Loss: 0.3554\n",
            "Epoch [5/10], Step [291/296], Loss: 0.3467\n",
            "Epoch [5/10], Loss: 0.3845, Test accuracy: 87.28%\n",
            "Epoch duration: 147.06 seconds\n",
            "Estimated time left: 12.26 minutes\n",
            "Epoch [6/10], Step [1/296], Loss: 0.3270\n",
            "Epoch [6/10], Step [11/296], Loss: 0.4674\n",
            "Epoch [6/10], Step [21/296], Loss: 0.2915\n",
            "Epoch [6/10], Step [31/296], Loss: 0.3552\n",
            "Epoch [6/10], Step [41/296], Loss: 0.3156\n",
            "Epoch [6/10], Step [51/296], Loss: 0.4147\n",
            "Epoch [6/10], Step [61/296], Loss: 0.2318\n",
            "Epoch [6/10], Step [71/296], Loss: 0.4641\n",
            "Epoch [6/10], Step [81/296], Loss: 0.2763\n",
            "Epoch [6/10], Step [91/296], Loss: 0.3473\n",
            "Epoch [6/10], Step [101/296], Loss: 0.3218\n",
            "Epoch [6/10], Step [111/296], Loss: 0.3005\n",
            "Epoch [6/10], Step [121/296], Loss: 0.3129\n",
            "Epoch [6/10], Step [131/296], Loss: 0.3265\n",
            "Epoch [6/10], Step [141/296], Loss: 0.2827\n",
            "Epoch [6/10], Step [151/296], Loss: 0.4398\n",
            "Epoch [6/10], Step [161/296], Loss: 0.2668\n",
            "Epoch [6/10], Step [171/296], Loss: 0.2528\n",
            "Epoch [6/10], Step [181/296], Loss: 0.2966\n",
            "Epoch [6/10], Step [191/296], Loss: 0.2356\n",
            "Epoch [6/10], Step [201/296], Loss: 0.3368\n",
            "Epoch [6/10], Step [211/296], Loss: 0.3161\n",
            "Epoch [6/10], Step [221/296], Loss: 0.3182\n",
            "Epoch [6/10], Step [231/296], Loss: 0.2711\n",
            "Epoch [6/10], Step [241/296], Loss: 0.3093\n",
            "Epoch [6/10], Step [251/296], Loss: 0.3223\n",
            "Epoch [6/10], Step [261/296], Loss: 0.3016\n",
            "Epoch [6/10], Step [271/296], Loss: 0.2522\n",
            "Epoch [6/10], Step [281/296], Loss: 0.4147\n",
            "Epoch [6/10], Step [291/296], Loss: 0.2602\n",
            "Epoch [6/10], Loss: 0.3326, Test accuracy: 86.77%\n",
            "Epoch duration: 146.53 seconds\n",
            "Estimated time left: 9.77 minutes\n",
            "Epoch [7/10], Step [1/296], Loss: 0.3643\n",
            "Epoch [7/10], Step [11/296], Loss: 0.2222\n",
            "Epoch [7/10], Step [21/296], Loss: 0.2454\n",
            "Epoch [7/10], Step [31/296], Loss: 0.2962\n",
            "Epoch [7/10], Step [41/296], Loss: 0.3081\n",
            "Epoch [7/10], Step [51/296], Loss: 0.3505\n",
            "Epoch [7/10], Step [61/296], Loss: 0.4721\n",
            "Epoch [7/10], Step [71/296], Loss: 0.3519\n",
            "Epoch [7/10], Step [81/296], Loss: 0.4252\n",
            "Epoch [7/10], Step [91/296], Loss: 0.2812\n",
            "Epoch [7/10], Step [101/296], Loss: 0.1969\n",
            "Epoch [7/10], Step [111/296], Loss: 0.3259\n",
            "Epoch [7/10], Step [121/296], Loss: 0.2483\n",
            "Epoch [7/10], Step [131/296], Loss: 0.3584\n",
            "Epoch [7/10], Step [141/296], Loss: 0.3119\n",
            "Epoch [7/10], Step [151/296], Loss: 0.2622\n",
            "Epoch [7/10], Step [161/296], Loss: 0.2926\n",
            "Epoch [7/10], Step [171/296], Loss: 0.2145\n",
            "Epoch [7/10], Step [181/296], Loss: 0.2558\n",
            "Epoch [7/10], Step [191/296], Loss: 0.2698\n",
            "Epoch [7/10], Step [201/296], Loss: 0.2499\n",
            "Epoch [7/10], Step [211/296], Loss: 0.2958\n",
            "Epoch [7/10], Step [221/296], Loss: 0.2623\n",
            "Epoch [7/10], Step [231/296], Loss: 0.3308\n",
            "Epoch [7/10], Step [241/296], Loss: 0.2722\n",
            "Epoch [7/10], Step [251/296], Loss: 0.2617\n",
            "Epoch [7/10], Step [261/296], Loss: 0.2496\n",
            "Epoch [7/10], Step [271/296], Loss: 0.3523\n",
            "Epoch [7/10], Step [281/296], Loss: 0.3173\n",
            "Epoch [7/10], Step [291/296], Loss: 0.2783\n",
            "Epoch [7/10], Loss: 0.3113, Test accuracy: 89.35%\n",
            "Epoch duration: 145.98 seconds\n",
            "Estimated time left: 7.30 minutes\n",
            "Epoch [8/10], Step [1/296], Loss: 0.2587\n",
            "Epoch [8/10], Step [11/296], Loss: 0.3483\n",
            "Epoch [8/10], Step [21/296], Loss: 0.4030\n",
            "Epoch [8/10], Step [31/296], Loss: 0.2794\n",
            "Epoch [8/10], Step [41/296], Loss: 0.3892\n",
            "Epoch [8/10], Step [51/296], Loss: 0.2439\n",
            "Epoch [8/10], Step [61/296], Loss: 0.2270\n",
            "Epoch [8/10], Step [71/296], Loss: 0.2854\n",
            "Epoch [8/10], Step [81/296], Loss: 0.2807\n",
            "Epoch [8/10], Step [91/296], Loss: 0.3374\n",
            "Epoch [8/10], Step [101/296], Loss: 0.2655\n",
            "Epoch [8/10], Step [111/296], Loss: 0.2483\n",
            "Epoch [8/10], Step [121/296], Loss: 0.3907\n",
            "Epoch [8/10], Step [131/296], Loss: 0.2739\n",
            "Epoch [8/10], Step [141/296], Loss: 0.2795\n",
            "Epoch [8/10], Step [151/296], Loss: 0.1889\n",
            "Epoch [8/10], Step [161/296], Loss: 0.3034\n",
            "Epoch [8/10], Step [171/296], Loss: 0.3382\n",
            "Epoch [8/10], Step [181/296], Loss: 0.3838\n",
            "Epoch [8/10], Step [191/296], Loss: 0.2885\n",
            "Epoch [8/10], Step [201/296], Loss: 0.3950\n",
            "Epoch [8/10], Step [211/296], Loss: 0.1896\n",
            "Epoch [8/10], Step [221/296], Loss: 0.4193\n",
            "Epoch [8/10], Step [231/296], Loss: 0.1695\n",
            "Epoch [8/10], Step [241/296], Loss: 0.2907\n",
            "Epoch [8/10], Step [251/296], Loss: 0.2058\n",
            "Epoch [8/10], Step [261/296], Loss: 0.3021\n",
            "Epoch [8/10], Step [271/296], Loss: 0.3178\n",
            "Epoch [8/10], Step [281/296], Loss: 0.2239\n",
            "Epoch [8/10], Step [291/296], Loss: 0.1825\n",
            "Epoch [8/10], Loss: 0.2813, Test accuracy: 84.32%\n",
            "Epoch duration: 146.73 seconds\n",
            "Estimated time left: 4.89 minutes\n",
            "Epoch [9/10], Step [1/296], Loss: 0.3617\n",
            "Epoch [9/10], Step [11/296], Loss: 0.2822\n",
            "Epoch [9/10], Step [21/296], Loss: 0.2138\n",
            "Epoch [9/10], Step [31/296], Loss: 0.2002\n",
            "Epoch [9/10], Step [41/296], Loss: 0.2371\n",
            "Epoch [9/10], Step [51/296], Loss: 0.2563\n",
            "Epoch [9/10], Step [61/296], Loss: 0.3012\n",
            "Epoch [9/10], Step [71/296], Loss: 0.2842\n",
            "Epoch [9/10], Step [81/296], Loss: 0.1930\n",
            "Epoch [9/10], Step [91/296], Loss: 0.2595\n",
            "Epoch [9/10], Step [101/296], Loss: 0.2983\n",
            "Epoch [9/10], Step [111/296], Loss: 0.2544\n",
            "Epoch [9/10], Step [121/296], Loss: 0.3889\n",
            "Epoch [9/10], Step [131/296], Loss: 0.1127\n",
            "Epoch [9/10], Step [141/296], Loss: 0.2428\n",
            "Epoch [9/10], Step [151/296], Loss: 0.1420\n",
            "Epoch [9/10], Step [161/296], Loss: 0.3829\n",
            "Epoch [9/10], Step [171/296], Loss: 0.2820\n",
            "Epoch [9/10], Step [181/296], Loss: 0.3547\n",
            "Epoch [9/10], Step [191/296], Loss: 0.3310\n",
            "Epoch [9/10], Step [201/296], Loss: 0.2130\n",
            "Epoch [9/10], Step [211/296], Loss: 0.2473\n",
            "Epoch [9/10], Step [221/296], Loss: 0.2396\n",
            "Epoch [9/10], Step [231/296], Loss: 0.2728\n",
            "Epoch [9/10], Step [241/296], Loss: 0.1790\n",
            "Epoch [9/10], Step [251/296], Loss: 0.1684\n",
            "Epoch [9/10], Step [261/296], Loss: 0.2053\n",
            "Epoch [9/10], Step [271/296], Loss: 0.2025\n",
            "Epoch [9/10], Step [281/296], Loss: 0.2205\n",
            "Epoch [9/10], Step [291/296], Loss: 0.2809\n",
            "Epoch [9/10], Loss: 0.2487, Test accuracy: 93.32%\n",
            "Epoch duration: 146.73 seconds\n",
            "Estimated time left: 2.45 minutes\n",
            "Epoch [10/10], Step [1/296], Loss: 0.2265\n",
            "Epoch [10/10], Step [11/296], Loss: 0.1662\n",
            "Epoch [10/10], Step [21/296], Loss: 0.3410\n",
            "Epoch [10/10], Step [31/296], Loss: 0.2367\n",
            "Epoch [10/10], Step [41/296], Loss: 0.1731\n",
            "Epoch [10/10], Step [51/296], Loss: 0.2164\n",
            "Epoch [10/10], Step [61/296], Loss: 0.1525\n",
            "Epoch [10/10], Step [71/296], Loss: 0.3264\n",
            "Epoch [10/10], Step [81/296], Loss: 0.1384\n",
            "Epoch [10/10], Step [91/296], Loss: 0.1341\n",
            "Epoch [10/10], Step [101/296], Loss: 0.1650\n",
            "Epoch [10/10], Step [111/296], Loss: 0.2537\n",
            "Epoch [10/10], Step [121/296], Loss: 0.1801\n",
            "Epoch [10/10], Step [131/296], Loss: 0.2018\n",
            "Epoch [10/10], Step [141/296], Loss: 0.2848\n",
            "Epoch [10/10], Step [151/296], Loss: 0.5605\n",
            "Epoch [10/10], Step [161/296], Loss: 0.2636\n",
            "Epoch [10/10], Step [171/296], Loss: 0.3473\n",
            "Epoch [10/10], Step [181/296], Loss: 0.2029\n",
            "Epoch [10/10], Step [191/296], Loss: 0.2207\n",
            "Epoch [10/10], Step [201/296], Loss: 0.1714\n",
            "Epoch [10/10], Step [211/296], Loss: 0.2715\n",
            "Epoch [10/10], Step [221/296], Loss: 0.3157\n",
            "Epoch [10/10], Step [231/296], Loss: 0.2283\n",
            "Epoch [10/10], Step [241/296], Loss: 0.2234\n",
            "Epoch [10/10], Step [251/296], Loss: 0.1618\n",
            "Epoch [10/10], Step [261/296], Loss: 0.2442\n",
            "Epoch [10/10], Step [271/296], Loss: 0.3178\n",
            "Epoch [10/10], Step [281/296], Loss: 0.1643\n",
            "Epoch [10/10], Step [291/296], Loss: 0.1620\n",
            "Epoch [10/10], Loss: 0.2260, Test accuracy: 93.79%\n",
            "Epoch duration: 146.90 seconds\n",
            "Estimated time left: 0.00 minutes\n",
            "Total training time: 24.47 minutes\n",
            "Dataset preparation and model training completed.\n"
          ]
        }
      ]
    }
  ]
}